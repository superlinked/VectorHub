{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Real Estate NLQ (Natural Language Querying) Agent\n",
        "\n",
        "This notebook shows how to make a real estate agent that supports natural language queries. It's built using the Superlinked framework and mixes vector search with agent-style logic to handle different kinds of user inputs.\n",
        "\n",
        "The idea is pretty straightforward here: instead of making people click through filters and dropdowns, we let them just say what they want. The system takes that plain English query, figures out the intent, and routes it to the right operation—whether that's a basic search, a recommendation, a market insight, or even a comparison across cities.\n",
        "\n",
        "Superlinked takes care of the vector-based matching, so it can handle queries like “family-friendly homes near Toronto with 2 bedrooms under \\$300,000” and actually return relevant results—even if those tags aren’t explicitly in the data.\n",
        "\n",
        "There’s also an LLM in the mix (GPT-4), which helps classify the type of query and adds reasoning when needed. That’s what brings in the agentic behavior—it’s not just matching text, it’s making decisions about *what* kind of task to run and even how to tweak the query if it’s too restrictive or vague.\n",
        "\n",
        "## What We're Using\n",
        "\n",
        "The dataset includes standard property info—price, number of beds and baths, full address, city, province. On top of that, there’s demographic context like population and median income, which helps when answering more nuanced questions like “Is this a good investment area?” or “What suits a young family?”\n",
        "\n",
        "If you want to try this out with the same dataset, you can grab it here:\n",
        "[Download the data](https://drive.google.com/file/d/1WJmNuq0rR5XLWQzhjtt43D8Cz0he8zyq/view?usp=sharing)"
      ],
      "metadata": {
        "id": "YraDkEBkYkHW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wnsgB-KyvVd6"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pandas superlinked==28.3.1 openai python-dotenv huggingface_hub sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1WJmNuq0rR5XLWQzhjtt43D8Cz0he8zyq' -O data.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW3c-OglaR9-",
        "outputId": "121c6383-ed1d-4d4e-8c9b-927ddafc5311"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-22 12:44:14--  https://drive.google.com/uc?export=download&id=1WJmNuq0rR5XLWQzhjtt43D8Cz0he8zyq\n",
            "Resolving drive.google.com (drive.google.com)... 192.178.155.101, 192.178.155.113, 192.178.155.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|192.178.155.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1WJmNuq0rR5XLWQzhjtt43D8Cz0he8zyq&export=download [following]\n",
            "--2025-06-22 12:44:14--  https://drive.usercontent.google.com/download?id=1WJmNuq0rR5XLWQzhjtt43D8Cz0he8zyq&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 192.178.218.132, 2607:f8b0:4004:c25::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|192.178.218.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 73732 (72K) [application/octet-stream]\n",
            "Saving to: ‘data.csv’\n",
            "\n",
            "data.csv            100%[===================>]  72.00K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-06-22 12:44:15 (9.49 MB/s) - ‘data.csv’ saved [73732/73732]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tU6dRCtRvVd8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "from superlinked import framework as sl\n",
        "from dotenv import load_dotenv\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Any, Dict, List\n",
        "from openai import OpenAI\n",
        "from getpass import getpass\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Configure pandas display options\n",
        "pd.set_option(\"display.max_colwidth\", 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up your OpenAI and HF Token"
      ],
      "metadata": {
        "id": "lF2LzB1hm0tB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prompt for token (secure input)\n",
        "os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = getpass(\"Enter your Hugging Face token: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "HUGGINGFACE_HUB_TOKEN = os.environ[\"HUGGINGFACE_HUB_TOKEN\"]\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiL12Wtmm42D",
        "outputId": "7f0b822f-1315-4494-d531-c99d2c032c16"
      },
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Hugging Face token: ··········\n",
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N__Xnbb_vVd9"
      },
      "source": [
        "## Abstract Tool Class\n",
        "\n",
        "We're defining an abstract base class here that acts as a blueprint for all the tools the agent will use. Every tool will inherit from this and implement its own logic, but this makes sure they all follow the same structure.\n",
        "\n",
        "### Tool Class\n",
        "\n",
        "* Inherits from `ABC`, which means any subclass has to define the required methods.\n",
        "* `name()`: Just returns the tool’s name—nothing fancy.\n",
        "* `description()`: A short description of what the tool does.\n",
        "* `use()`: The core method that does the actual work. It takes in:\n",
        "\n",
        "  * `query`: The user's input in plain language\n",
        "  * `df`: Our real estate dataset\n",
        "  * `app`: The Superlinked app object to run queries\n",
        "  * `master_query`: A base NLQ query we reuse\n",
        "  * `openai_client`: Used when the tool needs to reason or generate something using GPT\n",
        "\n",
        "Each custom tool will override these methods. That’s how we keep the whole thing consistent while letting each one specialize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GcEbyTCKvVd-"
      },
      "outputs": [],
      "source": [
        "class Tool(ABC):\n",
        "    @abstractmethod\n",
        "    def name(self) -> str:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def description(self) -> str:\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def use(self, query: str, df: pd.DataFrame, app: Any, master_query: Any, openai_client: Any) -> str:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us0d2dNnvVd-"
      },
      "source": [
        "## RealEstate Schema\n",
        "\n",
        "This is where we define the schema for our property data using Superlinked. Think of it like a contract for what each property record should look like.\n",
        "\n",
        "### RealEstate Class\n",
        "\n",
        "* Inherits from `sl.Schema`, which is how Superlinked knows what fields to expect.\n",
        "* The fields are pretty standard:\n",
        "\n",
        "  * `id`: unique ID for each property\n",
        "  * `city`, `address`, `province`: basic location info as strings\n",
        "  * `price`, `median_family_income`: float values for anything money-related\n",
        "  * `number_beds`, `number_baths`, `population`: integer fields for count-style data\n",
        "\n",
        "Once defined, we just create an instance using `real_estate = RealEstate()`—this gets used later when setting up vector spaces and running queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SIiWUGX2vVd_"
      },
      "outputs": [],
      "source": [
        "class RealEstate(sl.Schema):\n",
        "    id: sl.IdField\n",
        "    city: sl.String\n",
        "    price: sl.Float\n",
        "    address: sl.String\n",
        "    number_beds: sl.Integer\n",
        "    number_baths: sl.Integer\n",
        "    province: sl.String\n",
        "    population: sl.Integer\n",
        "    median_family_income: sl.Float\n",
        "\n",
        "real_estate = RealEstate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbjN3qT2vVd_"
      },
      "source": [
        "### Data Loading and Preprocessing\n",
        "\n",
        "This part loads the real estate dataset (`data.csv`) and gets it into shape for the agent to use. Well just to note, I already made the `data.csv` as good as we can use for the ingestion. But I just wanted you guys to see how I did the data processing..\n",
        "\n",
        "### What’s Happening\n",
        "\n",
        "* We read the CSV into a pandas DataFrame and print how many records we got—just a sanity check.\n",
        "* If there’s no `id` column, we generate one using the row index. The tools need unique IDs to work. As the data we are using right now, I already made sure we have the `id` there, but this is just a sanity check.\n",
        "* Columns like `price`, `number_beds`, etc., are converted to the right types so we don’t run into weird bugs later (e.g., trying to run math on a string). I did this too already.\n",
        "* We also pull some stats from the dataset—max values for numeric fields and the list of unique cities/provinces. These are useful later for setting up vector spaces and filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5nY-lqSvVd_",
        "outputId": "1cdb882a-f3c9-4d14-a877-34910b548a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Loaded 1000 records\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading data...\")\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "print(f\"Loaded {len(df)} records\")\n",
        "\n",
        "# Ensure 'id' column exists\n",
        "if 'id' not in df.columns:\n",
        "    df['id'] = range(len(df))\n",
        "\n",
        "# Type conversions\n",
        "df['id'] = df['id'].astype(str)\n",
        "df['price'] = df['price'].astype(float)\n",
        "df['number_beds'] = df['number_beds'].astype(int)\n",
        "df['number_baths'] = df['number_baths'].astype(int)\n",
        "df['population'] = df['population'].astype(int)\n",
        "df['median_family_income'] = df['median_family_income'].astype(float)\n",
        "\n",
        "# Compute maximum values and unique categories\n",
        "max_price = df[\"price\"].max()\n",
        "max_beds = df[\"number_beds\"].max()\n",
        "max_baths = df[\"number_baths\"].max()\n",
        "max_population = df[\"population\"].max()\n",
        "max_median_family_income = df[\"median_family_income\"].max()\n",
        "unique_city_categories = pd.unique(df['city']).tolist()\n",
        "unique_province_categories = pd.unique(df['province']).tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohfnW4kovVeB"
      },
      "source": [
        "## Vector Space Setup\n",
        "\n",
        "Now we’re are going to set up the vector spaces that power both the semantic and numerical search.\n",
        "\n",
        "### This is how we are doing everything..\n",
        "\n",
        "* `address_space` uses `all-mpnet-base-v2` to semantically match address text. So if someone says “near downtown” or “close to Queen Street,” this model helps us find similar addresses—even if the exact words don’t appear. Eassy pissy until now. Nothing fancy\n",
        "* Then we’ve got numeric spaces for stuff like `price`, `beds`, `baths`, `population`, and `median_family_income`. These use min/max ranges and are set up in `MINIMUM` mode so that lower values are considered “closer” (e.g., cheaper properties are ranked higher if budget is a constraint).\n",
        "* Categorical spaces like `city` and `province` handle exact matches. So if the person is asking for the property in the `Toronto`, we make sure the filteration takes consider that into account.\n",
        "\n",
        "We also set up negative filtering so results that don’t match the requested city/province get penalized, as doing so, `relevance_score` will go down and the less relevant results will be showed in the bottom.\n",
        "\n",
        "Finally, we combine everything into one index that’s used to run the actual search. It bundles all the schema fields and spaces into a single structure that’s ready for querying.\n",
        "\n",
        "### Heads Up\n",
        "\n",
        "* That `all-mpnet-base-v2` model will need internet the first time you use it.\n",
        "* If your dataset changes, especially the price range, make sure to update the `max_value` settings or the scoring will be off.\n",
        "* If you're working with a big dataset, embedding performance can become a bottleneck—so keep an eye on that if things start to slow down. I mean you can bring in your own `LLM` and `embedding model` of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWem63JQvVeB",
        "outputId": "39d53eaf-a019-4f90-ee90-14a002b25c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up vector spaces...\n"
          ]
        }
      ],
      "source": [
        "print(\"Setting up vector spaces...\")\n",
        "address_space = sl.TextSimilaritySpace(text=real_estate.address, model=\"sentence-transformers/all-mpnet-base-v2\")\n",
        "price_space = sl.NumberSpace(number=real_estate.price, min_value=0, max_value=int(max_price), mode=sl.Mode.MINIMUM)\n",
        "beds_space = sl.NumberSpace(number=real_estate.number_beds, min_value=0, max_value=int(max_beds), mode=sl.Mode.MINIMUM)\n",
        "baths_space = sl.NumberSpace(number=real_estate.number_baths, min_value=0, max_value=int(max_baths), mode=sl.Mode.MINIMUM)\n",
        "population_space = sl.NumberSpace(number=real_estate.population, min_value=0, max_value=int(max_population), mode=sl.Mode.MINIMUM)\n",
        "income_space = sl.NumberSpace(number=real_estate.median_family_income, min_value=0, max_value=int(max_median_family_income), mode=sl.Mode.MINIMUM)\n",
        "city_space = sl.CategoricalSimilaritySpace(category_input=real_estate.city, categories=unique_city_categories, negative_filter=-1.0, uncategorized_as_category=False)\n",
        "province_space = sl.CategoricalSimilaritySpace(category_input=real_estate.province, categories=unique_province_categories, negative_filter=-1.0, uncategorized_as_category=False)\n",
        "\n",
        "index = sl.Index(\n",
        "    spaces=[address_space, price_space, beds_space, baths_space, population_space, income_space, city_space, province_space],\n",
        "    fields=[real_estate.id, real_estate.city, real_estate.price, real_estate.address, real_estate.number_beds, real_estate.number_baths, real_estate.province, real_estate.population, real_estate.median_family_income]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaMjkpAXvVeB"
      },
      "source": [
        "## OpenAI and Query Setup\n",
        "\n",
        "Now we are just going to utilize our OpenAI client and define how our natural language queries will be processed.\n",
        "\n",
        "* Sets up `OpenAIClientConfig` so Superlinked can use GPT to interpret queries.\n",
        "* Initializes the `OpenAI` client directly too, for when tools need to generate things like insights or reformulations.\n",
        "* Throws an error if the `OPEN_AI_API_KEY` isn’t set—so make sure that’s in the env before running anything. I mean general considerables right..\n",
        "\n",
        "Then we define some query parameters—like filters for city, province, price, beds, and baths. These let us control how much flexibility or strictness we want in the results.\n",
        "\n",
        "The actual NLQ query is configured with weighted scoring. Price gets a heavy boost (`price_weight=100.0`) because it’s usually the most important factor. Filters are applied as needed, and results are capped at 10 for now.\n",
        "\n",
        "The key thing here is the `with_natural_query` setting—it’s what makes the system actually understand free-form text instead of needing structured input.\n",
        "\n",
        "Just a few things to keep in mind:\n",
        "\n",
        "* You can always tweak the weights if ranking doesn’t feel quite right. That means, if you want you can give more preference to the number of beds for a query, or maybe population can be considerable factor for you.. So if you increase the weights, it increases the relevance of that filter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVBL6AGNvVeC",
        "outputId": "7acf3739-1229-4d00-8859-25cdf326c31c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up OpenAI and query...\n"
          ]
        }
      ],
      "source": [
        "print(\"Setting up OpenAI and query...\")\n",
        "try:\n",
        "    openai_config = sl.OpenAIClientConfig(api_key=OPENAI_API_KEY, model=\"gpt-4o\")\n",
        "    openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "except KeyError:\n",
        "    print(\"ERROR: Please set your OPEN_AI_API_KEY environment variable.\")\n",
        "    raise\n",
        "\n",
        "# Define query parameters\n",
        "address_param = sl.Param(\"query_address\")\n",
        "city_filter_param = sl.Param(\"filter_by_city\", options=unique_city_categories)\n",
        "province_filter_param = sl.Param(\"filter_by_province\", options=unique_province_categories)\n",
        "max_price_param = sl.Param(\"max_price\")\n",
        "min_beds_param = sl.Param(\"min_beds\")\n",
        "min_baths_param = sl.Param(\"min_baths\")\n",
        "\n",
        "# Define NLQ query with weights\n",
        "query = (\n",
        "    sl.Query(\n",
        "        index,\n",
        "        weights={\n",
        "            address_space: sl.Param(\"address_weight\", default=1.0),\n",
        "            price_space: sl.Param(\"price_weight\", default=100.0),  # Higher weight for price\n",
        "            city_space: sl.Param(\"city_weight\", default=1.0),\n",
        "            province_space: sl.Param(\"province_weight\", default=1.0),\n",
        "            beds_space: sl.Param(\"beds_weight\", default=1.0),\n",
        "            baths_space: sl.Param(\"baths_weight\", default=1.0),\n",
        "            population_space: sl.Param(\"population_weight\", default=0.2),\n",
        "            income_space: sl.Param(\"income_weight\", default=1.0),\n",
        "        }\n",
        "    )\n",
        "    .find(real_estate)\n",
        "    .similar(address_space, address_param, sl.Param(\"address_similar_weight\", default=1.0))\n",
        "    .filter(real_estate.city == city_filter_param)\n",
        "    .filter(real_estate.province == province_filter_param)\n",
        "    .filter(real_estate.price <= max_price_param)\n",
        "    .filter(real_estate.number_beds >= min_beds_param)\n",
        "    .filter(real_estate.number_baths >= min_baths_param)\n",
        "    .limit(sl.Param(\"limit\", default=10))\n",
        "    .with_natural_query(sl.Param(\"natural_query\"), openai_config)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0noH8glLvVeD"
      },
      "source": [
        "## Data Source and Executor\n",
        "\n",
        "Now we will use the Superlinked's in-memory ingestion, What it means is our data is loaded and processed entirely in RAM for fast operations, as having this, we can enable the faster operations without disk I/O. Ok so how it goes is...\n",
        "\n",
        "* The data source is created using `InMemorySource`, tied to our `RealEstate` schema. It uses `DataFrameParser` to map columns from the DataFrame into the right schema fields.\n",
        "* Then we initialize the `InMemoryExecutor`, which connects the data source and the vector index we built earlier.\n",
        "* Once everything’s wired up, we run the executor. That gives us the `app` object, which we use to actually execute queries.\n",
        "* Finally, the preprocessed DataFrame is loaded into the source so it’s ready to be queried.\n",
        "\n",
        "If you're working with bigger datasets, in-memory probably won’t scale. As but for production, Superlinked also supports persistent vector databases so that is all good there too..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qrbmnzr4vVeD",
        "outputId": "b7382b35-88b1-4a3b-a495-8213d9a666ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingesting 1000 records...\n",
            "Data ingestion complete.\n"
          ]
        }
      ],
      "source": [
        "# Data source setup\n",
        "source = sl.InMemorySource(\n",
        "    real_estate,\n",
        "    parser=sl.DataFrameParser(\n",
        "        schema=real_estate,\n",
        "        mapping={\n",
        "            real_estate.id: \"id\",\n",
        "            real_estate.city: \"city\",\n",
        "            real_estate.price: \"price\",\n",
        "            real_estate.address: \"address\",\n",
        "            real_estate.number_beds: \"number_beds\",\n",
        "            real_estate.number_baths: \"number_baths\",\n",
        "            real_estate.province: \"province\",\n",
        "            real_estate.population: \"population\",\n",
        "            real_estate.median_family_income: \"median_family_income\"\n",
        "        }\n",
        "    )\n",
        ")\n",
        "\n",
        "executor = sl.InMemoryExecutor(sources=[source], indices=[index])\n",
        "app = executor.run()\n",
        "\n",
        "print(f\"Ingesting {len(df)} records...\")\n",
        "source.put([df])\n",
        "print(\"Data ingestion complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk5ogCzsvVeD"
      },
      "source": [
        "## Utility Functions\n",
        "\n",
        "I have just setted up some Utility functions, I mean just couple of helpers to make the output from the query results usable and presentable.\n",
        "\n",
        "* `results_to_dataframe`: So it takes in the raw Superlinked query results and converts them into a pandas DataFrame. Keeps the NLQ relevance scores intact and sorts the results accordingly. If there’s nothing to show, it just returns an empty frame so nothing breaks downstream.\n",
        "\n",
        "* `format_property_display`: Cleans up how the results are shown. If we want detailed info, it formats things like price, address, and relevance score in a more readable way (like a table). If we just need a quick list, it can handle that too. The ordering sticks to how NLQ ranked it—no reordering on our end.\n",
        "\n",
        "These don’t touch the core logic, they’re just for better display and usability. So it's more like a post-processing logic..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "B02DeSFPvVeE"
      },
      "outputs": [],
      "source": [
        "def results_to_dataframe(query_results, original_df):\n",
        "    \"\"\"Convert query results to pandas DataFrame, preserving NLQ order.\"\"\"\n",
        "    if not query_results.entries:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    result_ids = [entry.id for entry in query_results.entries]\n",
        "    scores = [entry.metadata.score for entry in query_results.entries]\n",
        "\n",
        "    df_results = original_df[original_df['id'].astype(str).isin(result_ids)].copy()\n",
        "    id_to_score = dict(zip(result_ids, scores))\n",
        "    df_results['relevance_score'] = df_results['id'].astype(str).map(id_to_score)\n",
        "\n",
        "    # Sort by relevance score\n",
        "    df_results = df_results.sort_values('relevance_score', ascending=False)\n",
        "\n",
        "    return df_results\n",
        "\n",
        "def format_property_display(df_results, query_text, detailed=True):\n",
        "    \"\"\"Format property results for display, respecting NLQ order.\"\"\"\n",
        "    if len(df_results) == 0:\n",
        "        return \"No properties found.\"\n",
        "\n",
        "    output = []\n",
        "    if detailed:\n",
        "        show_columns = ['city', 'id', 'province', 'address', 'price', 'number_beds', 'number_baths', 'relevance_score']\n",
        "        df_display = df_results[show_columns].copy()\n",
        "        df_display['price'] = df_display['price'].apply(lambda x: f\"${x:,.0f}\")\n",
        "        df_display['relevance_score'] = df_display['relevance_score'].apply(lambda x: f\"{x:.3f}\")\n",
        "        output.append(df_display.to_string(index=False))\n",
        "    else:\n",
        "        for idx, row in df_results.iterrows():\n",
        "            output.append(f\"{idx+1}. {row['city']}, {row['province']} - ${row['price']:,.0f} - {row['number_beds']}bed/{row['number_baths']}bath\")\n",
        "\n",
        "    return \"\\n\".join(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDnnnqGBvVeE"
      },
      "source": [
        "## Agent Tools\n",
        "\n",
        "Ok so here are the different tools for our agentic setup, now each one is built for a specific kind of query so the system doesn’t just throw everything into one generic search. I have described more about these tools in the blog but here is the quick snippet reference of what each one of them does..\n",
        "\n",
        "* **PropertyRetrievalTool**: Just runs a straight-up search. It takes natural language queries like “2 bed room in Mississauga under 700K” and maps them to results using the NLQ engine.\n",
        "\n",
        "* **PropertyRecommendationTool**: Tries to infer what the user actually wants (budget, lifestyle, family size, etc.) and then gives ranked suggestions with reasoning, pros, and cons. LLM does the heavy lifting here after we get the relevant results from the NLQ side.\n",
        "\n",
        "* **QueryRefinementTool**: If a query gives barely any results (like too tight a budget), this tool steps in and suggests a smarter version of the query—like loosening price or location constraints. I mean we wanted to help the user as much as we can.\n",
        "\n",
        "* **NarrativeInsightTool**: Built for more analytical queries (e.g., “what’s a good investment in Toronto?”). It pulls stats from the data and then uses the LLM to generate a readable market insight.\n",
        "\n",
        "* **MultiStepQueryTool**: If the user asks to compare places or options, this tool breaks the query down into parts, runs them separately, and merges the results for a side-by-side view. This tool is more about how you can handle the complex queries...\n",
        "\n",
        "Every tool leans on the same NLQ pipeline for semantic matching, and taps into OpenAI when reasoning or generation is needed.\n",
        "\n",
        "So it's like\n",
        "\n",
        "`NLQ Pipeline -> Gives NLQ based results (based on the relevance score) -> passed to the agent -> Final results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "bQbz0GrKvVeE"
      },
      "outputs": [],
      "source": [
        "class PropertyRetrievalTool(Tool):\n",
        "    def name(self) -> str:\n",
        "        return \"PropertyRetrievalTool\"\n",
        "\n",
        "    def description(self) -> str:\n",
        "        return \"Retrieves properties based on natural language queries, leveraging NLQ intelligence for ranking\"\n",
        "\n",
        "    def use(self, query: str, df: pd.DataFrame, app: Any, master_query: Any, openai_client: Any) -> str:\n",
        "        try:\n",
        "            results = app.query(master_query, natural_query=query, limit=10)\n",
        "            df_results = results_to_dataframe(results, df)\n",
        "            if len(df_results) == 0:\n",
        "                # If there are no results found, pass it to the QueryRefinementTool to get the better response\n",
        "                refine_tool = QueryRefinementTool()\n",
        "                return refine_tool.use(query, df, app, master_query, openai_client)\n",
        "            return f\"Search Results for '{query}':\\n\\n{format_property_display(df_results, query, detailed=True)}\"\n",
        "        except Exception as e:\n",
        "            return f\"Error in property retrieval: {str(e)}\"\n",
        "\n",
        "class PropertyRecommendationTool(Tool):\n",
        "    def name(self) -> str:\n",
        "        return \"PropertyRecommendationTool\"\n",
        "\n",
        "    def description(self) -> str:\n",
        "        return \"Provides personalized property recommendations based on inferred user preferences\"\n",
        "\n",
        "    def use(self, query: str, df: pd.DataFrame, app: Any, master_query: Any, openai_client: Any) -> str:\n",
        "        # Infer user profile from query\n",
        "        profile_prompt = f\"\"\"\n",
        "        Extract user preferences from this query, such as budget, family size, commute preferences, or lifestyle (e.g., urban, family-friendly).\n",
        "        Query: \"{query}\"\n",
        "        Return a JSON object with inferred preferences (e.g., {{\"budget\": 800000, \"family_size\": 4}}). If none, return {{}}.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            profile_response = openai_client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": profile_prompt}],\n",
        "                temperature=0.3,\n",
        "                max_tokens=100\n",
        "            )\n",
        "            user_profile = eval(profile_response.choices[0].message.content.strip()) or {}\n",
        "        except Exception as e:\n",
        "            user_profile = {}\n",
        "            print(f\"Error inferring user profile: {str(e)}\")\n",
        "\n",
        "        # Fetch properties using NLQ\n",
        "        results = app.query(master_query, natural_query=query, limit=15)\n",
        "        df_results = results_to_dataframe(results, df)\n",
        "        if len(df_results) == 0:\n",
        "            return \"No properties found to recommend.\"\n",
        "\n",
        "        # Prepare property data (top properties from NLQ ranking)\n",
        "        properties_summary = [\n",
        "            {\n",
        "                'address': row['address'],\n",
        "                'city': row['city'],\n",
        "                'province': row['province'],\n",
        "                'price': int(row['price']),\n",
        "                'beds': int(row['number_beds']),\n",
        "                'baths': int(row['number_baths']),\n",
        "                'population': int(row['population']),\n",
        "                'median_income': int(row['median_family_income']),\n",
        "                'relevance': round(row['relevance_score'], 3)\n",
        "            }\n",
        "            for _, row in df_results.head(10).iterrows()\n",
        "        ]\n",
        "\n",
        "        # Generate recommendations\n",
        "        prompt = f\"\"\"\n",
        "        You are a real estate advisor. Provide recommendations based on:\n",
        "        Query: \"{query}\"\n",
        "        Inferred Profile: {user_profile}\n",
        "        Properties (ranked by NLQ relevance): {properties_summary}\n",
        "\n",
        "        The properties are already ranked by our intelligent NLQ system considering all factors including price relevance.\n",
        "        Provide:\n",
        "        1. Top 3 recommendations with reasons (include address) - respect the NLQ ranking\n",
        "        2. Pros and cons for each\n",
        "        3. Additional considerations (e.g., neighborhood, lifestyle fit)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = openai_client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.7,\n",
        "                max_tokens=800\n",
        "            )\n",
        "            recommendations = response.choices[0].message.content.strip()\n",
        "\n",
        "            # Use top properties from NLQ ranking (no additional sorting)\n",
        "            formatted_properties = format_property_display(df_results.head(5), query, detailed=True)\n",
        "            return f\"Recommendations for '{query}':\\n\\n{recommendations}\\n\\nProperty Listings (NLQ Ranked):\\n{formatted_properties}\"\n",
        "        except Exception as e:\n",
        "            return f\"Error generating recommendations: {str(e)}\"\n",
        "\n",
        "class QueryRefinementTool(Tool):\n",
        "    def name(self) -> str:\n",
        "        return \"QueryRefinementTool\"\n",
        "\n",
        "    def description(self) -> str:\n",
        "        return \"Refines queries when results are sparse or irrelevant\"\n",
        "\n",
        "    def use(self, query: str, df: pd.DataFrame, app: Any, master_query: Any, openai_client: Any) -> str:\n",
        "        # Try initial query\n",
        "        results = app.query(master_query, natural_query=query, limit=10)\n",
        "        df_results = results_to_dataframe(results, df)\n",
        "\n",
        "        if len(df_results) >= 3:\n",
        "            return f\"Search Results for '{query}':\\n\\n{format_property_display(df_results, query, detailed=True)}\"\n",
        "\n",
        "        # Refine query if fewer than 3 results\n",
        "        refine_prompt = f\"\"\"\n",
        "        The query \"{query}\" returned {len(df_results)} results. Suggest an alternative query to get more relevant results.\n",
        "        Consider relaxing filters (e.g., price, location) or expanding scope (e.g., nearby cities).\n",
        "        Return a single alternative query as a string.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = openai_client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": refine_prompt}],\n",
        "                temperature=0.3,\n",
        "                max_tokens=50\n",
        "            )\n",
        "            new_query = response.choices[0].message.content.strip()\n",
        "\n",
        "            # Try refined query\n",
        "            results = app.query(master_query, natural_query=new_query, limit=10)\n",
        "            df_new_results = results_to_dataframe(results, df)\n",
        "\n",
        "            if len(df_new_results) == 0:\n",
        "                return f\"No properties found for '{query}'. Suggested query '{new_query}' also returned no results.\"\n",
        "\n",
        "            return f\"\"\"\n",
        "Original Query: '{query}' returned {len(df_results)} results.\n",
        "Suggested Query: '{new_query}'\n",
        "Results for '{new_query}' (NLQ Ranked):\n",
        "{format_property_display(df_new_results, new_query, detailed=True)}\n",
        "            \"\"\"\n",
        "        except Exception as e:\n",
        "            return f\"Error refining query: {str(e)}\"\n",
        "\n",
        "class NarrativeInsightTool(Tool):\n",
        "    def name(self) -> str:\n",
        "        return \"NarrativeInsightTool\"\n",
        "\n",
        "    def description(self) -> str:\n",
        "        return \"Provides narrative insights for complex queries (e.g., investment potential)\"\n",
        "\n",
        "    def use(self, query: str, df: pd.DataFrame, app: Any, master_query: Any, openai_client: Any) -> str:\n",
        "        results = app.query(master_query, natural_query=query, limit=10)\n",
        "        df_results = results_to_dataframe(results, df)\n",
        "        if len(df_results) == 0:\n",
        "            return \"No properties found for analysis.\"\n",
        "\n",
        "        stats = {\n",
        "            'avg_price': int(df_results['price'].mean()),\n",
        "            'median_price': int(df_results['price'].median()),\n",
        "            'price_range': (int(df_results['price'].min()), int(df_results['price'].max())),\n",
        "            'avg_beds': round(df_results['number_beds'].mean(), 1),\n",
        "            'avg_baths': round(df_results['number_baths'].mean(), 1),\n",
        "            'cities': df_results['city'].value_counts().head(3).to_dict(),\n",
        "            'avg_income': int(df_results['median_family_income'].mean())\n",
        "        }\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Provide a narrative analysis for the query: \"{query}\"\n",
        "        Data: {stats}\n",
        "        Properties (NLQ ranked by relevance): {[{k: v for k, v in row.items() if k in ['address', 'city', 'price', 'number_beds', 'number_baths', 'relevance_score']} for _, row in df_results.head(5).iterrows()]}\n",
        "\n",
        "        Note: Properties are already intelligently ranked by our NLQ system considering price and other factors.\n",
        "        Include:\n",
        "        1. Market overview\n",
        "        2. Investment potential (if relevant)\n",
        "        3. Key considerations (e.g., location, price trends)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = openai_client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.7,\n",
        "                max_tokens=600\n",
        "            )\n",
        "            insights = response.choices[0].message.content.strip()\n",
        "            formatted_properties = format_property_display(df_results, query, detailed=True)\n",
        "            return f\"Insights for '{query}':\\n\\n{insights}\\n\\nProperty Listings (NLQ Ranked):\\n{formatted_properties}\"\n",
        "        except Exception as e:\n",
        "            return f\"Error generating insights: {str(e)}\"\n",
        "\n",
        "class MultiStepQueryTool(Tool):\n",
        "    def name(self) -> str:\n",
        "        return \"MultiStepQueryTool\"\n",
        "\n",
        "    def description(self) -> str:\n",
        "        return \"Handles queries requiring multiple NLQ calls (e.g., comparisons)\"\n",
        "\n",
        "    def use(self, query: str, df: pd.DataFrame, app: Any, master_query: Any, openai_client: Any) -> str:\n",
        "        # Detect if query involves comparison\n",
        "        compare_pattern = re.compile(r'\\b(compare|versus|vs\\.?)\\b', re.IGNORECASE)\n",
        "        if not compare_pattern.search(query):\n",
        "            return \"Query does not require comparison.\"\n",
        "\n",
        "        # Extract sub-queries\n",
        "        prompt = f\"\"\"\n",
        "        Split the query into sub-queries for comparison.\n",
        "        Query: \"{query}\"\n",
        "        Return a JSON list of sub-queries (e.g., [\"3 bedroom homes in Toronto\", \"3 bedroom homes in Kitchener\"]).\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = openai_client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.3,\n",
        "                max_tokens=100\n",
        "            )\n",
        "            sub_queries = eval(response.choices[0].message.content.strip())\n",
        "            if not isinstance(sub_queries, list) or len(sub_queries) < 2:\n",
        "                return \"Unable to split query for comparison.\"\n",
        "\n",
        "            # Run sub-queries (NLQ handles intelligent ranking)\n",
        "            results_dict = {}\n",
        "            for sub_query in sub_queries[:2]:  # Limit to 2 for simplicity\n",
        "                results = app.query(master_query, natural_query=sub_query, limit=5)\n",
        "                df_sub_results = results_to_dataframe(results, df)\n",
        "                results_dict[sub_query] = df_sub_results\n",
        "\n",
        "            # Generate comparison\n",
        "            data_str = \"\"\n",
        "            for sub_query, df_sub_results in results_dict.items():\n",
        "                data_str += f\"\\n{sub_query} (NLQ ranked):\\n\"\n",
        "                for _, row in df_sub_results.head(3).iterrows():\n",
        "                    data_str += f\"  - Address: {row['address']}, City: {row['city']}, Price: ${row['price']:,.0f}, Beds: {row['number_beds']}, Baths: {row['number_baths']}, Relevance: {row['relevance_score']:.3f}\\n\"\n",
        "\n",
        "            compare_prompt = f\"\"\"\n",
        "            Compare properties from these sub-queries (each ranked by NLQ intelligence):\n",
        "            {list(results_dict.keys())}\n",
        "            Data:\n",
        "            {data_str}\n",
        "\n",
        "            Note: Each property list is already ranked by our NLQ system considering all factors including price relevance.\n",
        "            Provide:\n",
        "            1. Side-by-side comparison (price, beds, baths, NLQ relevance)\n",
        "            2. Key differences (e.g., location, value, market positioning)\n",
        "            3. Recommendations for different buyer types\n",
        "            \"\"\"\n",
        "            response = openai_client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": compare_prompt}],\n",
        "                temperature=0.7,\n",
        "                max_tokens=800\n",
        "            )\n",
        "            comparison = response.choices[0].message.content.strip()\n",
        "\n",
        "            # Format results\n",
        "            output = [f\"Comparison for '{query}':\\n\\n{comparison}\"]\n",
        "            for sub_query, df_sub_results in results_dict.items():\n",
        "                if not df_sub_results.empty:\n",
        "                    output.append(f\"\\nResults for '{sub_query}' (NLQ Ranked):\\n{format_property_display(df_sub_results, sub_query, detailed=True)}\")\n",
        "\n",
        "            return \"\\n\".join(output)\n",
        "        except Exception as e:\n",
        "            return f\"Error processing comparison: {str(e)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwBsacjuvVeF"
      },
      "source": [
        "## RealEstateAgent Class\n",
        "\n",
        "Ok this is the main entry point—the class that actually runs the show when a query comes in. I will just run through how difefrent parts are glued..\n",
        "\n",
        "* **Init phase**: It wires up everything—stores the dataset, the executor, the pre-built NLQ query, and the OpenAI client. It also sets up all the tools and maps them by query type so that each kind of intent goes to the right handler.\n",
        "\n",
        "* **classify\\_query**: This is where we ask the LLM to figure out *what* the user wants—basic search, a recommendation, comparison, insight, etc. If something goes wrong, it just defaults to `retrieval` to keep things safe.\n",
        "\n",
        "* **process\\_query**: Given a user query, it runs classification and then hands it off to the right tool.\n",
        "\n",
        "In production or real life case, I think we can add logs around what category the query landed in and which tool ran—useful for debugging and understanding usage patterns.\n",
        "\n",
        "Caching frequent classifications could help too, especially if people tend to ask the same kind of stuff over and over."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "j1xAAZiUvVeF"
      },
      "outputs": [],
      "source": [
        "class RealEstateAgent:\n",
        "    def __init__(self, df, app, master_query, openai_client):\n",
        "        self.df = df\n",
        "        self.app = app\n",
        "        self.master_query = master_query\n",
        "        self.openai_client = openai_client\n",
        "        self.tools = [\n",
        "            PropertyRetrievalTool(),\n",
        "            PropertyRecommendationTool(),\n",
        "            QueryRefinementTool(),\n",
        "            NarrativeInsightTool(),\n",
        "            MultiStepQueryTool()\n",
        "        ]\n",
        "        self.category_to_tool = {\n",
        "            'retrieval': self.tools[0],\n",
        "            'recommendation': self.tools[1],\n",
        "            'refinement': self.tools[2],\n",
        "            'insight': self.tools[3],\n",
        "            'multistep': self.tools[4]\n",
        "        }\n",
        "\n",
        "    def classify_query(self, query: str) -> str:\n",
        "        valid_categories = {'retrieval', 'recommendation', 'refinement', 'insight', 'multistep'}\n",
        "        prompt = f\"\"\"\n",
        "Classify the query into one category based on its intent, returning only the category name ('retrieval' if unsure):\n",
        "- retrieval: Search for properties by criteria (e.g., location, price, bedrooms).\n",
        "- recommendation: Personalized property suggestions for user needs.\n",
        "- refinement: Strict criteria likely yielding few results, needing adjustment.\n",
        "- insight: Analysis, investment advice, or market trends.\n",
        "- multistep: Comparison or multiple criteria across locations.\n",
        "Query: \"{query}\"\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = self.openai_client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.3,\n",
        "                max_tokens=20\n",
        "            )\n",
        "            classification = response.choices[0].message.content.strip().lower()\n",
        "            return classification if classification in valid_categories else 'retrieval'\n",
        "        except Exception as e:\n",
        "            print(f\"Classification error: {str(e)}\")\n",
        "            return 'retrieval'\n",
        "\n",
        "    def process_query(self, query: str) -> str:\n",
        "        print(f\"\\nProcessing query: {query}\")\n",
        "        query_type = self.classify_query(query)\n",
        "        print(f\"Query classified as: {query_type}\")\n",
        "        tool = self.category_to_tool.get(query_type, self.tools[0])\n",
        "        return tool.use(query, self.df, self.app, self.master_query, self.openai_client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn7O45cdvVeF"
      },
      "source": [
        "## Execution and Testing\n",
        "\n",
        "This is where everything gets wired up and tested end-to-end.\n",
        "\n",
        "* First, we spin up the `RealEstateAgent` instance using all the pieces defined earlier.\n",
        "* Then we run a few sample queries—just to validate that each tool (retrieval, recommendation, refinement, insight, and multistep) is working as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGSj-X74vVeG",
        "outputId": "dabff4b1-03be-4ae5-8401-d5df13d07a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing agent...\n",
            "Agent ready.\n",
            "Running example queries...\n",
            "\n",
            "Processing query: 3 bedroom homes in Oshawa under $600,000\n",
            "Query classified as: retrieval\n",
            "Search Results for '3 bedroom homes in Oshawa under $600,000':\n",
            "\n",
            "  city  id province              address    price  number_beds  number_baths relevance_score\n",
            "Oshawa 171  Ontario #70 -53 TAUNTON RD E $520,000            3             3           0.418\n",
            "Oshawa 603  Ontario      145 BANTING AVE $499,900            6             5           0.417\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Processing query: I want to know which will be a good option for me if I live in Toronto, most expensive one\n",
            "Query classified as: recommendation\n",
            "Recommendations for 'I want to know which will be a good option for me if I live in Toronto, most expensive one':\n",
            "\n",
            "1. Top 3 recommendations:\n",
            "\n",
            "   a. #LPH19 -2095 LAKE SHORE BLVD W:\n",
            "   \n",
            "      Reasons: This property is the most expensive on the list, priced at $4,336,900. It has 3 bedrooms and 4 bathrooms, indicating a large space that can accommodate a family or multiple occupants comfortably.\n",
            "      \n",
            "   b. 209 BELLWOODS AVE:\n",
            "   \n",
            "      Reasons: The second most expensive property on the list, priced at $2,500,000. It has 4 bedrooms and 4 bathrooms, which is a good option for a large family or for someone who wants extra rooms for guests or office space.\n",
            "      \n",
            "   c. 43 WALMSLEY BLVD:\n",
            "   \n",
            "      Reasons: Priced at $1,998,000, it is the third most expensive on the list but still offers a good number of bedrooms (3) and a bathroom.\n",
            "\n",
            "2. Pros and Cons:\n",
            "\n",
            "   a. #LPH19 -2095 LAKE SHORE BLVD W:\n",
            "   \n",
            "      Pros: Large number of bedrooms and bathrooms, indicating a spacious property. The price indicates high quality and luxury.\n",
            "      \n",
            "      Cons: The high price may be beyond the budget of many buyers.\n",
            "      \n",
            "   b. 209 BELLWOODS AVE:\n",
            "   \n",
            "      Pros: Good number of bedrooms and bathrooms. The price indicates high-end features and quality.\n",
            "      \n",
            "      Cons: The price is still quite high, which may not suit all budgets.\n",
            "      \n",
            "   c. 43 WALMSLEY BLVD:\n",
            "   \n",
            "      Pros: Relatively lower price than the first two, while still offering a good number of bedrooms.\n",
            "      \n",
            "      Cons: Only one bathroom, which may not be convenient for larger families or multiple occupants.\n",
            "\n",
            "3. Additional considerations:\n",
            "   \n",
            "   It's also important to consider the neighborhood and how it fits with your lifestyle. For example, some areas may be closer to downtown, providing easy access to work, shopping, and entertainment. On the other hand, some people may prefer quieter, residential areas that may be further from these amenities. It's also worth checking the proximity to public transportation, schools, parks, and other amenities. Consider also the property's potential for appreciation, which can be a good investment for the future.\n",
            "\n",
            "Property Listings (NLQ Ranked):\n",
            "   city  id province                        address      price  number_beds  number_baths relevance_score\n",
            "Toronto   9  Ontario #LPH19 -2095 LAKE SHORE BLVD W $4,336,900            3             4          -0.351\n",
            "Toronto 489  Ontario              209 BELLWOODS AVE $2,500,000            4             4          -0.383\n",
            "Toronto 190  Ontario               43 WALMSLEY BLVD $1,998,000            3             1          -0.387\n",
            "Toronto 195  Ontario                411 CONCORD AVE $1,859,000            3             3          -0.389\n",
            "Toronto 357  Ontario              212 EDENBRIDGE DR $1,800,000            4             3          -0.390\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Processing query: 3 bedroom homes in Oshawa under $300,000\n",
            "Query classified as: retrieval\n",
            "\n",
            "Original Query: '3 bedroom homes in Oshawa under $300,000' returned 0 results.\n",
            "Suggested Query: '\"3 bedroom homes in Durham Region under $400,000\"'\n",
            "Results for '\"3 bedroom homes in Durham Region under $400,000\"' (NLQ Ranked):\n",
            "       city  id                  province                 address    price  number_beds  number_baths relevance_score\n",
            "    Calgary 263                   Alberta   84 Whitehaven Road NE $329,000            3             2           0.793\n",
            " St. John's 544 Newfoundland and Labrador     28 Chapman Crescent $199,900            3             1           0.790\n",
            " St. John's 148 Newfoundland and Labrador 193 Cumberland Crescent $190,000            3             2           0.790\n",
            " St. John's  30 Newfoundland and Labrador       162 Bennetts Road $369,900            3             2           0.788\n",
            " St. John's 658 Newfoundland and Labrador 127 Commonwealth Avenue $295,000            3             2           0.788\n",
            "Thunder Bay 723                   Ontario          71 Hull Avenue $329,900            3             1           0.788\n",
            "     Regina 315              Saskatchewan    2914 Avonhurst DRIVE $265,000            3             2           0.787\n",
            "     Regina 683              Saskatchewan          35 Hind STREET $159,900            3             1           0.785\n",
            "     Regina 547              Saskatchewan  4609 Green Rock ROAD E $395,000            3             3           0.784\n",
            " Lethbridge 596                   Alberta          12 Lynx Road N $388,000            3             3           0.783\n",
            "            \n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Processing query: What's a good investment in Toronto?\n",
            "Query classified as: insight\n",
            "Insights for 'What's a good investment in Toronto?':\n",
            "\n",
            "The Toronto real estate market has a wide range of properties available, with average prices around $577,158 and median prices around $589,000. The typical property in Toronto has around 1.6 bedrooms and 1.1 bathrooms. The price range for properties in the city extends from $415,000 to $695,000.\n",
            "\n",
            "The average income in Toronto is $97,000, so investing in properties can be a good way to generate income and build wealth. High demand and rising prices in the city indicate good potential for investment returns.\n",
            "\n",
            "Several properties have been identified as potentially good investments based on relevance scores calculated considering price and other factors. The property at #1808 -1 King St W is priced at $415,000, which is on the lower end of the price range, making it a potentially affordable investment option. This property has 1 bedroom and 1 bathroom. Other notable properties include #2009 -24 Wellesley St W priced at $599,000 with 2 bedrooms and 1 bathroom, and #906 -1190 Dundas St E priced at $579,000 with 1 bedroom and 1 bathroom. \n",
            "\n",
            "However, when considering an investment, factors beyond price and property features should be considered. The location of the property, proximity to amenities, and the neighborhood's potential for growth and development can greatly impact the property's value and rental income potential. It's also important to consider price trends in the area to understand if the investment is likely to appreciate in value over time. \n",
            "\n",
            "In conclusion, investing in Toronto's real estate can be lucrative given the city's broad price range, high demand, and the potential for property value appreciation. However, careful consideration of various factors is crucial for making a good investment.\n",
            "\n",
            "Property Listings (NLQ Ranked):\n",
            "   city  id province                  address    price  number_beds  number_baths relevance_score\n",
            "Toronto  25  Ontario       #1808 -1 KING ST W $415,000            1             1           0.418\n",
            "Toronto 592  Ontario #2009 -24 WELLESLEY ST W $599,000            2             1           0.418\n",
            "Toronto 699  Ontario   #906 -1190 DUNDAS ST E $579,000            1             1           0.418\n",
            "Toronto 914  Ontario  #201 -115 RICHMOND ST E $479,000            1             1           0.418\n",
            "Toronto 695  Ontario       #1606 -36 ZORRA ST $519,888            2             1           0.418\n",
            "Toronto  91  Ontario   #1608 -101 ERSKINE AVE $539,900            1             1           0.417\n",
            "Toronto 492  Ontario #907 -185 ROEHAMPTON AVE $609,900            2             1           0.417\n",
            "Toronto 164  Ontario     #325 -361 FRONT ST W $659,900            2             1           0.417\n",
            "Toronto 649  Ontario     #213 -525 WILSON AVE $675,000            2             2           0.417\n",
            "Toronto 706  Ontario      #2112 -101 PETER ST $695,000            2             1           0.417\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "Processing query: Compare 3 bedroom homes in Toronto and Kitchener\n",
            "Query classified as: multistep\n",
            "Comparison for 'Compare 3 bedroom homes in Toronto and Kitchener':\n",
            "\n",
            "1. Side-by-side comparison:\n",
            "\n",
            "   - The highest-priced 3-bedroom home in Toronto is listed at $1,149,999 with 2 bathrooms, whereas in Kitchener, the highest-priced 3-bedroom home is listed at $649,900 with 2 bathrooms. \n",
            "   \n",
            "   - The lowest-priced 3-bedroom home in Toronto is listed at $848,000 with 2 bathrooms, whereas in Kitchener, the lowest-priced 3-bedroom home is listed at $589,000 with 1 bathroom.\n",
            "   \n",
            "   - The NLQ relevance scores are fairly similar for both cities, with scores in the range of 0.415 to 0.419.\n",
            "\n",
            "2. Key differences:\n",
            "\n",
            "   - The most significant difference is location. Toronto is a larger and more populous city than Kitchener, and this is reflected in the higher property prices.  \n",
            "   \n",
            "   - The value of the properties in Kitchener is arguably better, as buyers can acquire similar properties (in terms of bedroom number) for significantly less money. \n",
            "\n",
            "   - The market positioning can vary depending on the specific locations within each city, the age of the properties, their condition, and the local amenities.\n",
            "\n",
            "3. Recommendations for different buyer types:\n",
            "\n",
            "   - First-time buyers or those with a lower budget might be better off looking in Kitchener, where prices are lower.\n",
            "   \n",
            "   - Investors or those looking for a property in a more vibrant city might prefer to buy in Toronto, even though prices are higher.\n",
            "   \n",
            "   - Buyers who prioritize having more than one bathroom in their home might prefer the Toronto properties, as all listed Toronto properties have 2 bathrooms, while one of the Kitchener properties only has 1.\n",
            "   \n",
            "   - Any decision should also take into account the buyer's personal and professional situation, including their workplace location, family needs, lifestyle preferences, and future plans.\n",
            "\n",
            "Results for '3 bedroom homes in Toronto' (NLQ Ranked):\n",
            "   city  id province           address      price  number_beds  number_baths relevance_score\n",
            "Toronto 508  Ontario 166 HIAWATHA RD W   $929,000            3             2           0.417\n",
            "Toronto 869  Ontario      299 OSLER ST   $848,000            3             2           0.417\n",
            "Toronto  54  Ontario      35 FOURTH ST $1,149,999            3             2           0.415\n",
            "Toronto 659  Ontario 108 ARMSTRONG AVE $1,189,000            3             2           0.415\n",
            "Toronto 140  Ontario        32 KIM CRT   $999,999            4             2           0.415\n",
            "\n",
            "Results for '3 bedroom homes in Kitchener' (NLQ Ranked):\n",
            "     city  id province                        address    price  number_beds  number_baths relevance_score\n",
            "Kitchener 471  Ontario           204 SCHLUETER Street $589,000            3             1           0.419\n",
            "Kitchener 918  Ontario 355 FISHER MILLS Road Unit# 75 $649,900            3             2           0.419\n",
            "Kitchener 156  Ontario         24 TIMBERLANE Crescent $624,900            3             2           0.419\n",
            "Kitchener 906  Ontario     400 WILSON Avenue Unit# 49 $599,000            3             3           0.418\n",
            "Kitchener 371  Ontario      110 FERGUS Avenue Unit# 1 $790,000            3             2           0.418\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print(\"Initializing agent...\")\n",
        "agent = RealEstateAgent(df, app, query, openai_client)\n",
        "print(\"Agent ready.\")\n",
        "\n",
        "# Run example queries\n",
        "print(\"Running example queries...\")\n",
        "queries = [\n",
        "    \"3 bedroom homes in Oshawa under $600,000\",\n",
        "    \"I want to know which will be a good option for me if I live in Toronto, most expensive one\",\n",
        "    \"3 bedroom homes in Oshawa under $300,000\",\n",
        "    \"What's a good investment in Toronto?\",\n",
        "    \"Compare 3 bedroom homes in Toronto and Kitchener\"\n",
        "]\n",
        "for q in queries:\n",
        "    result = agent.process_query(q)\n",
        "    print(result)\n",
        "    print(\"\\n\" + \"-\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wrapping It Up\n",
        "\n",
        "Well after everything, here we are... REAL ESTATE NLQ AGENT. Sounds cool guys.. And btw, I have wrote a complete blog for this, so if you are reading this standalone notebook, I would recommend read the blog to get better understanding."
      ],
      "metadata": {
        "id": "ckLTXnw1u3Yt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdmsHiLfvVeG",
        "outputId": "45054247-cb4d-4914-800b-a556ab93382f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a natural language query: 2 bedrooms and 2 bathrooms in Saint John?\n",
            "\n",
            "Processing query: 2 bedrooms and 2 bathrooms in Saint John?\n",
            "Query classified as: retrieval\n",
            "Search Results for '2 bedrooms and 2 bathrooms in Saint John?':\n",
            "\n",
            "      city  id      province               address    price  number_beds  number_baths relevance_score\n",
            "Saint John 206 New Brunswick 94 Brookview Crescent $299,900            3             2           0.419\n",
            "Saint John 598 New Brunswick        28 Pokiok Road $194,900            3             3           0.419\n",
            "Saint John 217 New Brunswick       2121 Route  845 $875,000            3             3           0.417\n"
          ]
        }
      ],
      "source": [
        "natural_query = input(\"Enter a natural language query: \")\n",
        "result = agent.process_query(natural_query)\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}